{"version":3,"sources":["../../../src/cli/migrations/migrate.ts"],"sourcesContent":["import { createWriteStream } from 'fs'\nimport { dedent } from 'ts-dedent'\nimport { exec } from 'child_process'\nimport * as fs from 'fs/promises'\nimport * as z from 'zod'\nimport decompress from 'decompress'\nimport getPort from 'get-port'\nimport http from 'node:http'\nimport https from 'node:https'\nimport Module from 'node:module'\nimport path from 'path'\nimport { buildDatabaseURL, parsePgProxyPort, appRoot } from '../util'\nimport { buildMigrations, getMigrationNames } from './builder'\nimport { findAndReplaceInFile } from '../util'\nimport { getConfig, type Config } from '../config'\nimport { start } from '../docker-commands/command-start'\nimport { stop } from '../docker-commands/command-stop'\nimport { withConfig } from '../configure/command-with-config'\nimport { pgBuilder, sqliteBuilder } from '../../migrators/query-builder'\nimport { Dialect } from '../../migrators/query-builder/builder'\n\n// Rather than run `npx prisma` we resolve the path to the prisma binary so that\n// we can be sure we are using the same version of Prisma that is a dependency of\n// the Electric client.\n// `Module.createRequire(import.meta.url)` creates an old-style `require()` function\n// that can be used to resolve the path to the prisma cli script using\n// `require.resolve()`.\n// We use the same method to resolve the path to `@electric-sql/prisma-generator`.\nconst require = Module.createRequire(import.meta.url)\nconst prismaPath = require.resolve('prisma')\nconst generatorPath = path.join(\n  path.dirname(require.resolve('@electric-sql/prisma-generator')),\n  'bin.js'\n)\n\nconst sqliteMigrationsFileName = 'migrations.ts'\nconst pgMigrationsFileName = 'pg-migrations.ts'\n\nexport const defaultPollingInterval = 1000 // in ms\n\nexport interface GeneratorOptions {\n  watch?: boolean\n  pollingInterval?: number\n  withMigrations?: string\n  debug?: boolean\n  exitOnError?: boolean\n  config: Config\n}\n\nexport async function generate(options: GeneratorOptions) {\n  const opts = {\n    exitOnError: true,\n    ...options,\n  }\n  let config = opts.config\n  if (opts.watch && opts.withMigrations) {\n    console.error(\n      'Cannot use --watch and --with-migrations at the same time. Please choose one.'\n    )\n    process.exit(1)\n  }\n  console.log('Generating Electric client...')\n  try {\n    if (opts.withMigrations) {\n      // Start new ElectricSQL and PostgreSQL containers\n      console.log('Starting ElectricSQL and PostgreSQL containers...')\n      // Remove the ELECTRIC_SERVICE and ELECTRIC_PROXY env vars\n      delete process.env.ELECTRIC_SERVICE\n      delete process.env.ELECTRIC_PROXY\n      config = getConfig({\n        ...config,\n        SERVICE: undefined,\n        PROXY: undefined,\n        ...(await withMigrationsConfig(config.CONTAINER_NAME)),\n      })\n      opts.config = config\n      await start({\n        config,\n        withPostgres: true,\n        detach: true,\n        exitOnDetached: false,\n      })\n      // Run the provided migrations command\n      console.log('Running migrations...')\n      const ret = withConfig(opts.withMigrations, opts.config)\n      if (ret.status !== 0) {\n        console.log(\n          'Failed to run migrations, --with-migrations command exited with error'\n        )\n        process.exit(1)\n      }\n    }\n    console.log('Service URL: ' + opts.config.SERVICE)\n    console.log('Proxy URL: ' + stripPasswordFromUrl(opts.config.PROXY))\n    // Generate the client\n    if (opts.watch) {\n      watchMigrations(opts)\n    } else {\n      await _generate(opts)\n    }\n  } finally {\n    if (opts.withMigrations) {\n      // Stop and remove the containers\n      console.log('Stopping ElectricSQL and PostgreSQL containers...')\n      await stop({\n        remove: true,\n        config,\n      })\n      console.log('Done')\n    }\n  }\n}\n\n/**\n * Periodically polls Electric's migration endpoint\n * to check for new migrations. Invokes `_generate`\n * when there are new migrations.\n */\nasync function watchMigrations(opts: GeneratorOptions) {\n  const config = opts.config\n  const pollingInterval = opts.pollingInterval\n  const pollMigrations = async () => {\n    // Create a unique temporary folder in which to save\n    // intermediate files without risking collisions\n    const tmpFolder = await fs.mkdtemp('.electric_migrations_tmp_')\n\n    try {\n      // Read migrations.js file to check latest migration version\n      const latestMigration = await getLatestMigration(opts)\n\n      let migrationEndpoint = config.SERVICE + '/api/migrations?dialect=sqlite'\n      if (latestMigration !== undefined) {\n        // Only fetch new migrations\n        migrationEndpoint = migrationEndpoint + `&version=${latestMigration}`\n      }\n\n      const migrationsPath = path.join(tmpFolder, 'migrations')\n      await fs.mkdir(migrationsPath)\n      const migrationsFolder = path.resolve(migrationsPath)\n\n      // Fetch new migrations from Electric endpoint and write them into `tmpFolder`\n      const gotNewMigrations = await fetchMigrations(\n        migrationEndpoint,\n        migrationsFolder,\n        tmpFolder\n      )\n\n      if (gotNewMigrations) {\n        const newMigrations = await getMigrationNames(migrationsFolder)\n        console.info('Discovered new migrations: ' + newMigrations.join(', '))\n        await _generate(opts)\n      }\n    } catch (e) {\n      console.error(JSON.stringify(e))\n    } finally {\n      // Delete our temporary directory\n      await fs.rm(tmpFolder, { recursive: true })\n      // We use `setTimeout` instead of `setInterval`\n      // because `setInterval` does not wait for the\n      // async function to finish. Since fetching and\n      // building the migrations may take a few seconds\n      // we want to avoid parallel invocations of `pollMigrations`\n      // which could happen if the time `pollMigrations`\n      // takes is longer than the timeout configured in `setInterval`.\n      setTimeout(pollMigrations, pollingInterval)\n    }\n  }\n\n  pollMigrations()\n}\n\n/**\n * Reads the migrations file that is bundled with the app\n * and returns the version of the latest migration.\n * Returns false if the migrations file does not exist.\n */\nasync function getLatestMigration(\n  opts: Omit<GeneratorOptions, 'watch'>\n): Promise<string | undefined> {\n  const migrationsFile = migrationsFilePath(opts, 'SQLite')\n\n  // Read the migrations file contents and parse it\n  // need to strip the `export default` before parsing.\n  // can't use dynamic import because it needs to be a .mjs file\n  // as node won't allow dynamically importing a .js file\n  // when using `\"type\": \"module\"` in package.json\n  let migrations: any = undefined\n  let migrationsFileContent = ''\n  try {\n    migrationsFileContent = await fs.readFile(migrationsFile, 'utf8')\n  } catch (e) {\n    // Migrations file does not exist\n    return undefined\n  }\n\n  const migrationsSchema = z\n    .object({\n      statements: z.string().array(),\n      version: z.string(),\n    })\n    .array()\n\n  try {\n    const prefix = 'export default '\n    const migrationsStr = migrationsFileContent.substring(prefix.length)\n    migrations = JSON.parse(migrationsStr)\n\n    const parsedMigrations = migrationsSchema.parse(migrations)\n    if (parsedMigrations.length === 0) return undefined\n    else {\n      const lastMigration = parsedMigrations[parsedMigrations.length - 1]\n      return lastMigration.version\n    }\n  } catch (e) {\n    throw new Error(\n      'Could not read migrations because they have an unexpected format.'\n    )\n  }\n}\n\nasync function bundleMigrationsFor(\n  dialect: Dialect,\n  opts: Omit<GeneratorOptions, 'watch'>,\n  tmpFolder: string\n) {\n  const config = opts.config\n  const folder = dialect === 'SQLite' ? 'migrations' : 'pg-migrations'\n  const migrationsPath = path.join(tmpFolder, folder)\n  await fs.mkdir(migrationsPath)\n  const dialectArg = dialect === 'SQLite' ? 'sqlite' : 'postgresql'\n  const migrationEndpoint =\n    config.SERVICE + `/api/migrations?dialect=${dialectArg}`\n\n  const migrationsFolder = path.resolve(migrationsPath)\n  const migrationsFile = migrationsFilePath(opts, dialect)\n\n  // Fetch the migrations from Electric endpoint and write them into `tmpFolder`\n  await fetchMigrations(migrationEndpoint, migrationsFolder, tmpFolder)\n\n  // Build the migrations\n  const builder = dialect === 'SQLite' ? sqliteBuilder : pgBuilder\n  return async () => {\n    await buildMigrations(migrationsFolder, migrationsFile, builder)\n  }\n}\n\n/**\n * This function migrates the application.\n * To this end, it fetches the migrations from Electric,\n * applies them to a fresh SQLite DB,\n * uses Prisma to introspect the DB and update the Prisma schema,\n * runs the generator to generate the updated Electric client,\n * and runs `buildMigrations` from `cli/migrator.ts`\n * to build the triggers and write the migrations and their triggers\n * to the config file in `.electric/@config/index.mjs`\n *\n * @param prismaSchema Path to the Prisma schema (relative path from the root folder of the app or absolute path).\n * @param migrationsFolder Absolute path to the migrations folder.\n * @param configFolder Absolute path to the configuration folder.\n */\nasync function _generate(opts: Omit<GeneratorOptions, 'watch'>) {\n  const config = opts.config\n  // Create a unique temporary folder in which to save\n  // intermediate files without risking collisions\n  const tmpFolder = await fs.mkdtemp('.electric_migrations_tmp_')\n  let generationFailed = false\n\n  try {\n    const buildSqliteMigrations = await bundleMigrationsFor(\n      'SQLite',\n      opts,\n      tmpFolder\n    )\n    const buildPgMigrations = await bundleMigrationsFor(\n      'Postgres',\n      opts,\n      tmpFolder\n    )\n\n    const prismaSchema = await createIntrospectionSchema(tmpFolder, opts)\n\n    // Introspect the created DB to update the Prisma schema\n    await introspectDB(prismaSchema)\n\n    // Generate the Electric client from the given introspected schema\n    await generateClient(prismaSchema, config.CLIENT_PATH)\n\n    const relativePath = path.relative(appRoot, config.CLIENT_PATH)\n    console.log(`Successfully generated Electric client at: ./${relativePath}`)\n\n    console.log('Building migrations...')\n    await buildSqliteMigrations()\n    await buildPgMigrations()\n    console.log('Successfully built migrations')\n\n    if (\n      ['nodenext', 'node16'].includes(\n        config.MODULE_RESOLUTION.toLocaleLowerCase()\n      )\n    ) {\n      await rewriteImportsForNodeNext(config.CLIENT_PATH)\n    }\n  } catch (e: any) {\n    generationFailed = true\n    console.error('generate command failed: ' + e)\n    throw e\n  } finally {\n    // Delete our temporary directory unless in debug mode\n    if (!opts.debug) await fs.rm(tmpFolder, { recursive: true })\n\n    // In case of process exit, make sure to run after folder removal\n    if (generationFailed && opts.exitOnError) process.exit(1)\n  }\n}\n\n/**\n * Generates the Electric client and the Prisma clients based off of the provided\n * introspected Prisma schema.\n * NOTE: exported for testing purposes only, not intended for external uses\n * @param prismaSchema path to the introspected Prisma schema\n * @param clientPath path to the directory where the client should be generated\n */\nexport async function generateClient(prismaSchema: string, clientPath: string) {\n  // Add custom validators (such as uuid) to the Prisma schema\n  await addValidators(prismaSchema)\n\n  // Modify snake_case table names to PascalCase\n  await capitaliseTableNames(prismaSchema)\n\n  // Read the contents of the Prisma schema\n  const introspectedSchema = await fs.readFile(prismaSchema, 'utf8')\n\n  // Add a generator for the Electric client to the Prisma schema\n  await createElectricClientSchema(introspectedSchema, prismaSchema, clientPath)\n\n  // Generate the Electric client from the Prisma schema\n  await generateElectricClient(prismaSchema)\n\n  // Add a generator for the Prisma client to the Prisma schema\n  await createPrismaClientSchema(introspectedSchema, prismaSchema, clientPath)\n\n  // Generate the Prisma client from the Prisma schema\n  await generatePrismaClient(prismaSchema)\n\n  // Perform necessary modifications to the generated client, like\n  // augmenting types, removing unused files, etc\n  await augmentGeneratedClient(clientPath)\n}\n\n/**\n * Performs any necessary modifications to the generated client such\n * as augmenting types, removing unused files, etc.\n * @param clientPath Path to the generated client directory\n */\nasync function augmentGeneratedClient(clientPath: string) {\n  // Modify the type of JSON input values in the generated Prisma client\n  // because we deviate from Prisma's typing for JSON values\n  await extendJsonType(clientPath)\n\n  // Replace the type of byte array input values in the generated Prisma client\n  // from `Buffer` to `Uint8Array` for better cross-environment support\n  await replaceByteArrayType(clientPath)\n\n  // Delete all files generated for the Prisma client, except the typings\n  await keepOnlyPrismaTypings(clientPath)\n}\n\n/**\n * Escapes file path for use in strings.\n * On Windows, replaces backslashes with double backslashes for string escaping.\n *\n * @param {string} inputPath - The file path to escape.\n * @return {string} The escaped file path.\n */\nfunction escapePathForString(inputPath: string): string {\n  return process.platform === 'win32'\n    ? inputPath.replace(/\\\\/g, '\\\\\\\\')\n    : inputPath\n}\n\nfunction buildProxyUrlForIntrospection(config: Config) {\n  return buildDatabaseURL({\n    user: 'prisma', // We use the \"prisma\" user to put the proxy into introspection mode\n    password: config.PG_PROXY_PASSWORD,\n    host: config.PG_PROXY_HOST,\n    port: parsePgProxyPort(config.PG_PROXY_PORT).port,\n    dbName: config.DATABASE_NAME,\n  })\n}\n\n/**\n * Creates a fresh Prisma schema in the provided folder.\n * The Prisma schema is initialised with a generator and a datasource.\n */\nasync function createIntrospectionSchema(\n  folder: string,\n  opts: GeneratorOptions\n) {\n  const config = opts.config\n  const prismaDir = path.join(folder, 'prisma')\n  const prismaSchemaFile = path.join(prismaDir, 'schema.prisma')\n  await fs.mkdir(prismaDir)\n  const proxyUrl = buildProxyUrlForIntrospection(config)\n  const schema = dedent`\n    datasource db {\n      provider = \"postgresql\"\n      url      = \"${proxyUrl}\"\n    }`\n  await fs.writeFile(prismaSchemaFile, schema)\n  return prismaSchemaFile\n}\n\n/**\n * Takes the Prisma schema that results from introspecting the DB\n * and extends it with a generator for the Electric client.\n * @param introspectedSchema The Prisma schema that results from introspecting the DB.\n * @param prismaSchemaFile Path to the Prisma schema file.\n * @returns The path to the Prisma schema file.\n */\nasync function createElectricClientSchema(\n  introspectedSchema: string,\n  prismaSchemaFile: string,\n  clientPath: string\n) {\n  const output = path.resolve(clientPath)\n\n  const schema = dedent`\n    generator electric {\n      provider      = \"node ${escapePathForString(generatorPath)}\"\n      output        = \"${escapePathForString(output)}\"\n      relationModel = \"false\"\n    }\n    \n    ${introspectedSchema}`\n\n  await fs.writeFile(prismaSchemaFile, schema)\n  return prismaSchemaFile\n}\n\n/**\n * Takes the Prisma schema that results from introspecting the DB\n * and extends it with a generator for the Prisma client.\n * @param introspectedSchema The Prisma schema that results from introspecting the DB.\n * @param prismaSchemaFile Path to the Prisma schema file.\n * @returns The path to the Prisma schema file.\n */\nasync function createPrismaClientSchema(\n  introspectedSchema: string,\n  prismaSchemaFile: string,\n  clientPath: string\n) {\n  const output = path.resolve(clientPath)\n\n  const schema = dedent`\n    generator client {\n      provider = \"prisma-client-js\"\n      output   = \"${escapePathForString(output)}\"\n    }\n    \n    ${introspectedSchema}`\n\n  await fs.writeFile(prismaSchemaFile, schema)\n  return prismaSchemaFile\n}\n\nasync function getFileLines(prismaSchema: string): Promise<Array<string>> {\n  const contents = await fs.readFile(prismaSchema, 'utf8')\n  return contents.split(/\\r?\\n/)\n}\n\n/**\n * Transforms the table names in the Prisma schema\n * such that they start with a capital letter.\n * All characters before the first letter are dropped\n * because Prisma requires model names to start with a (capital) letter.\n * @param prismaSchema Path to the Prisma schema file.\n */\nasync function capitaliseTableNames(prismaSchema: string): Promise<void> {\n  const lines = await getFileLines(prismaSchema)\n  const casedLines = doCapitaliseTableNames(lines)\n  // Write the modified Prisma schema to the file\n  await fs.writeFile(prismaSchema, casedLines.join('\\n'))\n}\n\n/**\n * @param lines Individual lines of the Prisma schema\n * @returns The modified lines.\n */\nexport function doCapitaliseTableNames(lines: string[]): string[] {\n  const replacements: Map<string, string> = new Map() // maps table names to their PascalCased model name\n  const modelNameToDbName: Map<string, string> = new Map() // maps the PascalCased model names to their original table name\n\n  // Prisma requires model names to adhere to the regex: [A-Za-z][A-Za-z0-9_]*\n  const modelRegex = /^\\s*model\\s+([A-Za-z][A-Za-z0-9_]*)\\s*{/\n  const getModelName = (ln: string) => ln.match(modelRegex)?.[1]\n\n  lines.forEach((ln, idx) => {\n    const tableName = getModelName(ln)\n    if (tableName) {\n      // Capitalise the first letter due to a bug with lowercase model names in Prisma's DMMF\n      // that leads to inconsistent type names in the generated client\n      // which in turn leads to type errors in the generated Electric client.\n      const modelName = capitaliseFirstLetter(tableName)\n\n      // Replace the model name on this line\n      const newLn = ln.replace(modelRegex, (_, _tableName) => {\n        return `model ${modelName} {`\n      })\n      lines[idx] = newLn\n\n      replacements.set(tableName, modelName)\n      modelNameToDbName.set(modelName, tableName)\n    }\n  })\n\n  // Go over the schema again but now\n  // replace references to the old table names\n  // by the new model name when we are inside\n  // the definition of a model\n  let modelName: string | undefined\n  let modelHasMapAttribute = false\n  // we're inside a model definition if we have a model name\n  const insideModel = () => modelName !== undefined\n  lines = lines.flatMap((ln) => {\n    modelName = getModelName(ln) ?? modelName\n\n    if (insideModel() && ln.trim().startsWith('}')) {\n      // we're exiting the model definition\n      const tableName = modelNameToDbName.get(modelName!)!\n      modelName = undefined\n      // if no `@@map` annotation was added by Prisma add one ourselves\n      if (!modelHasMapAttribute) {\n        return [`  @@map(\"${tableName}\")`, ln]\n      }\n      modelHasMapAttribute = false\n      return ln\n    }\n\n    // the regex below matches a line containing @@map(\"originalTableName\")\n    const nameMappingRegex = /^\\s*@@map\\(\"(.*)\"\\)\\s*$/\n    const mapAttribute = ln.match(nameMappingRegex)\n    if (insideModel() && mapAttribute !== null) {\n      // store the mapping from the model name to the original DB name\n      modelHasMapAttribute = true\n      const originalTableName = mapAttribute[1]\n      modelNameToDbName.set(modelName!, originalTableName)\n    }\n\n    if (insideModel()) {\n      // the regex below matches the beginning of a string\n      // followed by two identifiers separated by a space\n      // (first identifier is the column name, second is its type)\n      const reg = /^(\\s*\\w+\\s+)(\\w+)/\n      return ln.replace(reg, (_match, columnName, typeName) => {\n        const newTypeName = replacements.get(typeName) ?? typeName\n        return columnName + newTypeName\n      })\n    }\n\n    return ln\n  })\n\n  return lines\n}\n\nasync function introspectDB(prismaSchema: string): Promise<void> {\n  await executeShellCommand(\n    `node ${prismaPath} db pull --schema=\"${prismaSchema}\"`,\n    'Introspection script exited with error code: '\n  )\n}\n\n/**\n * Adds validators to the Prisma schema.\n * @param prismaSchema Path to the Prisma schema\n */\nasync function addValidators(prismaSchema: string): Promise<void> {\n  const lines = await getFileLines(removeComments(prismaSchema))\n  const newLines = lines.map(addValidator)\n  // Write the modified Prisma schema to the file\n  await fs.writeFile(prismaSchema, newLines.join('\\n'))\n}\n\n/**\n * Adds a validator to the Prisma schema line if needed.\n * @param ln A line from the Prisma schema\n */\nfunction addValidator(ln: string): string {\n  const field = parseFields(ln)[0] // try to parse a field (the line could be something else than a field)\n\n  if (field) {\n    const intValidator = '@zod.number.int().gte(-2147483648).lte(2147483647)'\n    const floatValidator = '@zod.custom.use(z.number().or(z.nan()))'\n\n    // Map attributes to validators\n    const attributeValidatorMapping = new Map([\n      ['@db.Uuid', '@zod.string.uuid()'],\n      ['@db.SmallInt', '@zod.number.int().gte(-32768).lte(32767)'],\n      ['@db.Int', intValidator],\n      ['@db.DoublePrecision', floatValidator],\n      ['@db.Real', floatValidator],\n    ])\n    const attribute = field.attributes\n      .map((a) => a.type)\n      .find((a) => attributeValidatorMapping.has(a))\n\n    if (attribute) {\n      return ln + ' /// ' + attributeValidatorMapping.get(attribute)!\n    } else {\n      // No attribute validators,\n      // check if the field's type requires a validator\n      const typeValidatorMapping = new Map([\n        ['Int', intValidator],\n        ['Int?', intValidator],\n        ['Int[]', intValidator],\n        ['Float', floatValidator],\n        ['Float?', floatValidator],\n        ['Float[]', floatValidator],\n      ])\n      const typeValidator = typeValidatorMapping.get(field.type)\n\n      if (typeValidator) {\n        return ln + ' /// ' + typeValidator\n      } else {\n        return ln\n      }\n    }\n  } else {\n    return ln\n  }\n}\n\nasync function generateElectricClient(prismaSchema: string): Promise<void> {\n  await executeShellCommand(\n    `node ${prismaPath} generate --schema=\"${prismaSchema}\"`,\n    'Generator script exited with error code: '\n  )\n}\n\nasync function generatePrismaClient(prismaSchema: string): Promise<void> {\n  await executeShellCommand(\n    `node ${prismaPath} generate --schema=\"${prismaSchema}\"`,\n    'Generator script exited with error code: '\n  )\n}\n\nasync function executeShellCommand(\n  command: string,\n  errMsg: string\n): Promise<void> {\n  return new Promise((resolve, reject) => {\n    const proc = exec(command, { cwd: appRoot }, (error, _stdout, _stderr) => {\n      if (error) {\n        console.error(error)\n      }\n    })\n\n    proc.on('close', (code) => {\n      if (code === 0) {\n        // Success\n        resolve()\n      } else {\n        reject(errMsg + code)\n      }\n    })\n  })\n}\n\n/**\n * Fetches the migrations from the provided endpoint,\n * unzips them and writes them to the `writeTo` location.\n */\nasync function fetchMigrations(\n  endpoint: string,\n  writeTo: string,\n  tmpFolder: string\n): Promise<boolean> {\n  const options = new URL(endpoint)\n  const zipFile = path.join(tmpFolder, 'migrations.zip')\n  const requestModule =\n    options.protocol === 'http:'\n      ? http\n      : options.protocol === 'https:'\n      ? https\n      : undefined\n\n  if (requestModule === undefined)\n    throw new TypeError(\n      `Protocol \"${options.protocol}\" not supported. Expected \"http:\" or \"https:\"`\n    )\n\n  const gotNewMigrations = await new Promise<boolean>((resolve, reject) => {\n    const req = requestModule.get(options, (response) => {\n      if (response.statusCode === 204) {\n        // No new migrations\n        resolve(false)\n      } else if (response.statusCode === 200) {\n        const migrationsZipFile = createWriteStream(zipFile)\n        response.pipe(migrationsZipFile)\n        migrationsZipFile.on('finish', () => resolve(true))\n      } else {\n        // Other status code, indicating a problem\n        reject(\n          `Failed to fetch migrations from Electric. Got ${response.statusCode} status code.`\n        )\n      }\n    })\n\n    req.on('error', reject)\n  })\n\n  // Unzip the migrations\n  if (gotNewMigrations) {\n    await decompress(zipFile, writeTo)\n  }\n\n  return gotNewMigrations\n}\n\nfunction migrationsFilePath(\n  opts: Omit<GeneratorOptions, 'watch'>,\n  sqlDialect: Dialect\n) {\n  const outFolder = path.resolve(opts.config.CLIENT_PATH)\n  const migrationsFileName =\n    sqlDialect === 'SQLite' ? sqliteMigrationsFileName : pgMigrationsFileName\n  return path.join(outFolder, migrationsFileName)\n}\n\nfunction capitaliseFirstLetter(word: string): string {\n  return word.charAt(0).toUpperCase() + word.substring(1)\n}\n\n// The below is duplicated code from the generator\n// TODO: move it to a separate helper package\n//       also move the model parsing to the package\n//       also move the removing comments function\n\nexport type Attribute = {\n  type: `@${string}`\n  args: Array<string>\n}\nexport type Field = {\n  field: string\n  type: string\n  attributes: Array<Attribute>\n}\n\n/**\n * Removes all line comments from a string.\n * A line comment is a comment that starts with *exactly* `//`.\n * It does not remove comments starting with `///`.\n */\nfunction removeComments(str: string): string {\n  const commentRegex = /(?<=[^/])\\/\\/(?=[^/]).*$/g // matches // until end of the line (does not match more than 2 slashes)\n  return str.replaceAll(commentRegex, '')\n}\n\n/**\n * Takes the body of a model and returns\n * an array of fields defined by the model.\n * @param body Body of a model\n * @returns Fields defined by the model\n */\nfunction parseFields(body: string): Array<Field> {\n  // The regex below matches the fields of a model (it assumes there are no comments at the end of the line)\n  // It uses named captured groups to capture the field name, its type, and optional attributes\n  // the type can be `type` or `type?` or `type[]`\n  const fieldRegex =\n    /^\\s*(?<field>\\w+)\\s+(?<type>[\\w]+(\\?|(\\[]))?)\\s*(?<attributes>((@[\\w.]+\\s*)|(@[\\w.]+\\(.*\\)+\\s*))+)?\\s*$/gm\n  const fieldMatches = [...body.matchAll(fieldRegex)]\n  const fs = fieldMatches.map(\n    (match) =>\n      match.groups as { field: string; type: string; attributes?: string }\n  )\n\n  return fs.map((f) => ({\n    ...f,\n    attributes: parseAttributes(f.attributes ?? ''),\n  }))\n}\n\n/**\n * Takes a string of attributes, e.g. `@id @db.Timestamp(2)`,\n * and returns an array of attributes, e.g. `['@id', '@db.Timestamp(2)]`.\n * @param attributes String of attributes\n * @returns Array of attributes.\n */\nfunction parseAttributes(attributes: string): Array<Attribute> {\n  // Matches each attribute in a string of attributes\n  // e.g. @id @db.Timestamp(2)\n  // The optional args capture group matches anything\n  // but not @or newline because that would be the start of a new attribute\n  const attributeRegex = /(?<type>@[\\w.]+)(?<args>\\([^@\\n\\r]+\\))?/g\n  const matches = [...attributes.matchAll(attributeRegex)]\n  return matches.map((m) => {\n    const { type, args } = m.groups! as { type: string; args?: string }\n    const noParens = args?.substring(1, args.length - 1) // arguments without starting '(' and closing ')'\n    const parsedArgs = noParens?.split(',')?.map((arg) => arg.trim()) ?? []\n    return {\n      type: type as `@${string}`,\n      args: parsedArgs,\n    }\n  })\n}\n\n/*\n * Modifies Prisma's `InputJsonValue` type to include `null`\n */\nfunction extendJsonType(prismaDir: string): Promise<void> {\n  const prismaTypings = path.join(prismaDir, 'index.d.ts')\n  const inputJsonValueRegex = /^\\s*export\\s*type\\s*InputJsonValue\\s*(=)\\s*/gm\n  const replacement = 'export type InputJsonValue = null | '\n  return findAndReplaceInFile(inputJsonValueRegex, replacement, prismaTypings)\n}\n\n/*\n * Replaces Prisma's `Buffer` type for byte arrays to the more generic `Uint8Array`\n */\nfunction replaceByteArrayType(prismaDir: string): Promise<void> {\n  const prismaTypings = path.join(prismaDir, 'index.d.ts')\n  return fs.appendFile(\n    prismaTypings,\n    // omit 'set' property as it conflicts with the DAL setter prop name\n    \"\\n\\ntype Buffer = Omit<Uint8Array, 'set'>\\n\"\n  )\n}\n\nasync function keepOnlyPrismaTypings(prismaDir: string): Promise<void> {\n  const contents = await fs.readdir(prismaDir)\n  // Delete all files except the generated Electric client and the Prisma typings\n  const proms = contents.map(async (fileOrDir) => {\n    const filePath = path.join(prismaDir, fileOrDir)\n    if (fileOrDir === 'index.d.ts') {\n      // rename this file to `prismaClient.d.ts`\n      return fs.rename(filePath, path.join(prismaDir, 'prismaClient.d.ts'))\n    } else if (fileOrDir !== 'index.ts') {\n      // delete the file or folder\n      return fs.rm(filePath, { recursive: true })\n    }\n  })\n  await Promise.all(proms)\n}\n\nasync function rewriteImportsForNodeNext(clientDir: string): Promise<void> {\n  const file = path.join(clientDir, 'index.ts')\n  const content = await fs.readFile(file, 'utf8')\n  const newContent = content\n    .replace(\"from './migrations';\", \"from './migrations.js';\")\n    .replace(\"from './prismaClient';\", \"from './prismaClient.js';\")\n  await fs.writeFile(file, newContent)\n}\n\nasync function withMigrationsConfig(containerName: string) {\n  return {\n    HTTP_PORT: await getPort(),\n    PG_PROXY_PORT: (await getPort()).toString(),\n    DATABASE_PORT: await getPort(),\n    SERVICE_HOST: 'localhost',\n    PG_PROXY_HOST: 'localhost',\n    DATABASE_REQUIRE_SSL: false,\n    // Random container name to avoid collisions\n    CONTAINER_NAME: `${containerName}-migrations-${Math.random()\n      .toString(36)\n      .slice(6)}`,\n  }\n}\n\nfunction stripPasswordFromUrl(url: string): string {\n  const parsed = new URL(url)\n  if (parsed.password) {\n    parsed.password = '********'\n  }\n  return parsed.toString()\n}\n"],"mappings":"AAAA,SAAS,yBAAyB;AAClC,SAAS,cAAc;AACvB,SAAS,YAAY;AACrB,YAAY,QAAQ;AACpB,YAAY,OAAO;AACnB,OAAO,gBAAgB;AACvB,OAAO,aAAa;AACpB,OAAO,UAAU;AACjB,OAAO,WAAW;AAClB,OAAO,YAAY;AACnB,OAAO,UAAU;AACjB,SAAS,kBAAkB,kBAAkB,eAAe;AAC5D,SAAS,iBAAiB,yBAAyB;AACnD,SAAS,4BAA4B;AACrC,SAAS,iBAA8B;AACvC,SAAS,aAAa;AACtB,SAAS,YAAY;AACrB,SAAS,kBAAkB;AAC3B,SAAS,WAAW,qBAAqB;AAUzC,MAAMA,WAAU,OAAO,cAAc,YAAY,GAAG;AACpD,MAAM,aAAaA,SAAQ,QAAQ,QAAQ;AAC3C,MAAM,gBAAgB,KAAK;AAAA,EACzB,KAAK,QAAQA,SAAQ,QAAQ,gCAAgC,CAAC;AAAA,EAC9D;AACF;AAEA,MAAM,2BAA2B;AACjC,MAAM,uBAAuB;AAEtB,MAAM,yBAAyB;AAWtC,eAAsB,SAAS,SAA2B;AACxD,QAAM,OAAO;AAAA,IACX,aAAa;AAAA,IACb,GAAG;AAAA,EACL;AACA,MAAI,SAAS,KAAK;AAClB,MAAI,KAAK,SAAS,KAAK,gBAAgB;AACrC,YAAQ;AAAA,MACN;AAAA,IACF;AACA,YAAQ,KAAK,CAAC;AAAA,EAChB;AACA,UAAQ,IAAI,+BAA+B;AAC3C,MAAI;AACF,QAAI,KAAK,gBAAgB;AAEvB,cAAQ,IAAI,mDAAmD;AAE/D,aAAO,QAAQ,IAAI;AACnB,aAAO,QAAQ,IAAI;AACnB,eAAS,UAAU;AAAA,QACjB,GAAG;AAAA,QACH,SAAS;AAAA,QACT,OAAO;AAAA,QACP,GAAI,MAAM,qBAAqB,OAAO,cAAc;AAAA,MACtD,CAAC;AACD,WAAK,SAAS;AACd,YAAM,MAAM;AAAA,QACV;AAAA,QACA,cAAc;AAAA,QACd,QAAQ;AAAA,QACR,gBAAgB;AAAA,MAClB,CAAC;AAED,cAAQ,IAAI,uBAAuB;AACnC,YAAM,MAAM,WAAW,KAAK,gBAAgB,KAAK,MAAM;AACvD,UAAI,IAAI,WAAW,GAAG;AACpB,gBAAQ;AAAA,UACN;AAAA,QACF;AACA,gBAAQ,KAAK,CAAC;AAAA,MAChB;AAAA,IACF;AACA,YAAQ,IAAI,kBAAkB,KAAK,OAAO,OAAO;AACjD,YAAQ,IAAI,gBAAgB,qBAAqB,KAAK,OAAO,KAAK,CAAC;AAEnE,QAAI,KAAK,OAAO;AACd,sBAAgB,IAAI;AAAA,IACtB,OAAO;AACL,YAAM,UAAU,IAAI;AAAA,IACtB;AAAA,EACF,UAAE;AACA,QAAI,KAAK,gBAAgB;AAEvB,cAAQ,IAAI,mDAAmD;AAC/D,YAAM,KAAK;AAAA,QACT,QAAQ;AAAA,QACR;AAAA,MACF,CAAC;AACD,cAAQ,IAAI,MAAM;AAAA,IACpB;AAAA,EACF;AACF;AAOA,eAAe,gBAAgB,MAAwB;AACrD,QAAM,SAAS,KAAK;AACpB,QAAM,kBAAkB,KAAK;AAC7B,QAAM,iBAAiB,YAAY;AAGjC,UAAM,YAAY,MAAM,GAAG,QAAQ,2BAA2B;AAE9D,QAAI;AAEF,YAAM,kBAAkB,MAAM,mBAAmB,IAAI;AAErD,UAAI,oBAAoB,OAAO,UAAU;AACzC,UAAI,oBAAoB,QAAW;AAEjC,4BAAoB,oBAAoB,YAAY,eAAe;AAAA,MACrE;AAEA,YAAM,iBAAiB,KAAK,KAAK,WAAW,YAAY;AACxD,YAAM,GAAG,MAAM,cAAc;AAC7B,YAAM,mBAAmB,KAAK,QAAQ,cAAc;AAGpD,YAAM,mBAAmB,MAAM;AAAA,QAC7B;AAAA,QACA;AAAA,QACA;AAAA,MACF;AAEA,UAAI,kBAAkB;AACpB,cAAM,gBAAgB,MAAM,kBAAkB,gBAAgB;AAC9D,gBAAQ,KAAK,gCAAgC,cAAc,KAAK,IAAI,CAAC;AACrE,cAAM,UAAU,IAAI;AAAA,MACtB;AAAA,IACF,SAAS,GAAG;AACV,cAAQ,MAAM,KAAK,UAAU,CAAC,CAAC;AAAA,IACjC,UAAE;AAEA,YAAM,GAAG,GAAG,WAAW,EAAE,WAAW,KAAK,CAAC;AAQ1C,iBAAW,gBAAgB,eAAe;AAAA,IAC5C;AAAA,EACF;AAEA,iBAAe;AACjB;AAOA,eAAe,mBACb,MAC6B;AAC7B,QAAM,iBAAiB,mBAAmB,MAAM,QAAQ;AAOxD,MAAI,aAAkB;AACtB,MAAI,wBAAwB;AAC5B,MAAI;AACF,4BAAwB,MAAM,GAAG,SAAS,gBAAgB,MAAM;AAAA,EAClE,SAAS,GAAG;AAEV,WAAO;AAAA,EACT;AAEA,QAAM,mBAAmB,EACtB,OAAO;AAAA,IACN,YAAY,EAAE,OAAO,EAAE,MAAM;AAAA,IAC7B,SAAS,EAAE,OAAO;AAAA,EACpB,CAAC,EACA,MAAM;AAET,MAAI;AACF,UAAM,SAAS;AACf,UAAM,gBAAgB,sBAAsB,UAAU,OAAO,MAAM;AACnE,iBAAa,KAAK,MAAM,aAAa;AAErC,UAAM,mBAAmB,iBAAiB,MAAM,UAAU;AAC1D,QAAI,iBAAiB,WAAW;AAAG,aAAO;AAAA,SACrC;AACH,YAAM,gBAAgB,iBAAiB,iBAAiB,SAAS,CAAC;AAClE,aAAO,cAAc;AAAA,IACvB;AAAA,EACF,SAAS,GAAG;AACV,UAAM,IAAI;AAAA,MACR;AAAA,IACF;AAAA,EACF;AACF;AAEA,eAAe,oBACb,SACA,MACA,WACA;AACA,QAAM,SAAS,KAAK;AACpB,QAAM,SAAS,YAAY,WAAW,eAAe;AACrD,QAAM,iBAAiB,KAAK,KAAK,WAAW,MAAM;AAClD,QAAM,GAAG,MAAM,cAAc;AAC7B,QAAM,aAAa,YAAY,WAAW,WAAW;AACrD,QAAM,oBACJ,OAAO,UAAU,2BAA2B,UAAU;AAExD,QAAM,mBAAmB,KAAK,QAAQ,cAAc;AACpD,QAAM,iBAAiB,mBAAmB,MAAM,OAAO;AAGvD,QAAM,gBAAgB,mBAAmB,kBAAkB,SAAS;AAGpE,QAAM,UAAU,YAAY,WAAW,gBAAgB;AACvD,SAAO,YAAY;AACjB,UAAM,gBAAgB,kBAAkB,gBAAgB,OAAO;AAAA,EACjE;AACF;AAgBA,eAAe,UAAU,MAAuC;AAC9D,QAAM,SAAS,KAAK;AAGpB,QAAM,YAAY,MAAM,GAAG,QAAQ,2BAA2B;AAC9D,MAAI,mBAAmB;AAEvB,MAAI;AACF,UAAM,wBAAwB,MAAM;AAAA,MAClC;AAAA,MACA;AAAA,MACA;AAAA,IACF;AACA,UAAM,oBAAoB,MAAM;AAAA,MAC9B;AAAA,MACA;AAAA,MACA;AAAA,IACF;AAEA,UAAM,eAAe,MAAM,0BAA0B,WAAW,IAAI;AAGpE,UAAM,aAAa,YAAY;AAG/B,UAAM,eAAe,cAAc,OAAO,WAAW;AAErD,UAAM,eAAe,KAAK,SAAS,SAAS,OAAO,WAAW;AAC9D,YAAQ,IAAI,gDAAgD,YAAY,EAAE;AAE1E,YAAQ,IAAI,wBAAwB;AACpC,UAAM,sBAAsB;AAC5B,UAAM,kBAAkB;AACxB,YAAQ,IAAI,+BAA+B;AAE3C,QACE,CAAC,YAAY,QAAQ,EAAE;AAAA,MACrB,OAAO,kBAAkB,kBAAkB;AAAA,IAC7C,GACA;AACA,YAAM,0BAA0B,OAAO,WAAW;AAAA,IACpD;AAAA,EACF,SAAS,GAAQ;AACf,uBAAmB;AACnB,YAAQ,MAAM,8BAA8B,CAAC;AAC7C,UAAM;AAAA,EACR,UAAE;AAEA,QAAI,CAAC,KAAK;AAAO,YAAM,GAAG,GAAG,WAAW,EAAE,WAAW,KAAK,CAAC;AAG3D,QAAI,oBAAoB,KAAK;AAAa,cAAQ,KAAK,CAAC;AAAA,EAC1D;AACF;AASA,eAAsB,eAAe,cAAsB,YAAoB;AAE7E,QAAM,cAAc,YAAY;AAGhC,QAAM,qBAAqB,YAAY;AAGvC,QAAM,qBAAqB,MAAM,GAAG,SAAS,cAAc,MAAM;AAGjE,QAAM,2BAA2B,oBAAoB,cAAc,UAAU;AAG7E,QAAM,uBAAuB,YAAY;AAGzC,QAAM,yBAAyB,oBAAoB,cAAc,UAAU;AAG3E,QAAM,qBAAqB,YAAY;AAIvC,QAAM,uBAAuB,UAAU;AACzC;AAOA,eAAe,uBAAuB,YAAoB;AAGxD,QAAM,eAAe,UAAU;AAI/B,QAAM,qBAAqB,UAAU;AAGrC,QAAM,sBAAsB,UAAU;AACxC;AASA,SAAS,oBAAoB,WAA2B;AACtD,SAAO,QAAQ,aAAa,UACxB,UAAU,QAAQ,OAAO,MAAM,IAC/B;AACN;AAEA,SAAS,8BAA8B,QAAgB;AACrD,SAAO,iBAAiB;AAAA,IACtB,MAAM;AAAA;AAAA,IACN,UAAU,OAAO;AAAA,IACjB,MAAM,OAAO;AAAA,IACb,MAAM,iBAAiB,OAAO,aAAa,EAAE;AAAA,IAC7C,QAAQ,OAAO;AAAA,EACjB,CAAC;AACH;AAMA,eAAe,0BACb,QACA,MACA;AACA,QAAM,SAAS,KAAK;AACpB,QAAM,YAAY,KAAK,KAAK,QAAQ,QAAQ;AAC5C,QAAM,mBAAmB,KAAK,KAAK,WAAW,eAAe;AAC7D,QAAM,GAAG,MAAM,SAAS;AACxB,QAAM,WAAW,8BAA8B,MAAM;AACrD,QAAM,SAAS;AAAA;AAAA;AAAA,oBAGG,QAAQ;AAAA;AAE1B,QAAM,GAAG,UAAU,kBAAkB,MAAM;AAC3C,SAAO;AACT;AASA,eAAe,2BACb,oBACA,kBACA,YACA;AACA,QAAM,SAAS,KAAK,QAAQ,UAAU;AAEtC,QAAM,SAAS;AAAA;AAAA,8BAEa,oBAAoB,aAAa,CAAC;AAAA,yBACvC,oBAAoB,MAAM,CAAC;AAAA;AAAA;AAAA;AAAA,MAI9C,kBAAkB;AAEtB,QAAM,GAAG,UAAU,kBAAkB,MAAM;AAC3C,SAAO;AACT;AASA,eAAe,yBACb,oBACA,kBACA,YACA;AACA,QAAM,SAAS,KAAK,QAAQ,UAAU;AAEtC,QAAM,SAAS;AAAA;AAAA;AAAA,oBAGG,oBAAoB,MAAM,CAAC;AAAA;AAAA;AAAA,MAGzC,kBAAkB;AAEtB,QAAM,GAAG,UAAU,kBAAkB,MAAM;AAC3C,SAAO;AACT;AAEA,eAAe,aAAa,cAA8C;AACxE,QAAM,WAAW,MAAM,GAAG,SAAS,cAAc,MAAM;AACvD,SAAO,SAAS,MAAM,OAAO;AAC/B;AASA,eAAe,qBAAqB,cAAqC;AACvE,QAAM,QAAQ,MAAM,aAAa,YAAY;AAC7C,QAAM,aAAa,uBAAuB,KAAK;AAE/C,QAAM,GAAG,UAAU,cAAc,WAAW,KAAK,IAAI,CAAC;AACxD;AAMO,SAAS,uBAAuB,OAA2B;AAChE,QAAM,eAAoC,oBAAI,IAAI;AAClD,QAAM,oBAAyC,oBAAI,IAAI;AAGvD,QAAM,aAAa;AACnB,QAAM,eAAe,CAAC,OAAe,GAAG,MAAM,UAAU,IAAI,CAAC;AAE7D,QAAM,QAAQ,CAAC,IAAI,QAAQ;AACzB,UAAM,YAAY,aAAa,EAAE;AACjC,QAAI,WAAW;AAIb,YAAMC,aAAY,sBAAsB,SAAS;AAGjD,YAAM,QAAQ,GAAG,QAAQ,YAAY,CAAC,GAAG,eAAe;AACtD,eAAO,SAASA,UAAS;AAAA,MAC3B,CAAC;AACD,YAAM,GAAG,IAAI;AAEb,mBAAa,IAAI,WAAWA,UAAS;AACrC,wBAAkB,IAAIA,YAAW,SAAS;AAAA,IAC5C;AAAA,EACF,CAAC;AAMD,MAAI;AACJ,MAAI,uBAAuB;AAE3B,QAAM,cAAc,MAAM,cAAc;AACxC,UAAQ,MAAM,QAAQ,CAAC,OAAO;AAC5B,gBAAY,aAAa,EAAE,KAAK;AAEhC,QAAI,YAAY,KAAK,GAAG,KAAK,EAAE,WAAW,GAAG,GAAG;AAE9C,YAAM,YAAY,kBAAkB,IAAI,SAAU;AAClD,kBAAY;AAEZ,UAAI,CAAC,sBAAsB;AACzB,eAAO,CAAC,YAAY,SAAS,MAAM,EAAE;AAAA,MACvC;AACA,6BAAuB;AACvB,aAAO;AAAA,IACT;AAGA,UAAM,mBAAmB;AACzB,UAAM,eAAe,GAAG,MAAM,gBAAgB;AAC9C,QAAI,YAAY,KAAK,iBAAiB,MAAM;AAE1C,6BAAuB;AACvB,YAAM,oBAAoB,aAAa,CAAC;AACxC,wBAAkB,IAAI,WAAY,iBAAiB;AAAA,IACrD;AAEA,QAAI,YAAY,GAAG;AAIjB,YAAM,MAAM;AACZ,aAAO,GAAG,QAAQ,KAAK,CAAC,QAAQ,YAAY,aAAa;AACvD,cAAM,cAAc,aAAa,IAAI,QAAQ,KAAK;AAClD,eAAO,aAAa;AAAA,MACtB,CAAC;AAAA,IACH;AAEA,WAAO;AAAA,EACT,CAAC;AAED,SAAO;AACT;AAEA,eAAe,aAAa,cAAqC;AAC/D,QAAM;AAAA,IACJ,QAAQ,UAAU,sBAAsB,YAAY;AAAA,IACpD;AAAA,EACF;AACF;AAMA,eAAe,cAAc,cAAqC;AAChE,QAAM,QAAQ,MAAM,aAAa,eAAe,YAAY,CAAC;AAC7D,QAAM,WAAW,MAAM,IAAI,YAAY;AAEvC,QAAM,GAAG,UAAU,cAAc,SAAS,KAAK,IAAI,CAAC;AACtD;AAMA,SAAS,aAAa,IAAoB;AACxC,QAAM,QAAQ,YAAY,EAAE,EAAE,CAAC;AAE/B,MAAI,OAAO;AACT,UAAM,eAAe;AACrB,UAAM,iBAAiB;AAGvB,UAAM,4BAA4B,oBAAI,IAAI;AAAA,MACxC,CAAC,YAAY,oBAAoB;AAAA,MACjC,CAAC,gBAAgB,0CAA0C;AAAA,MAC3D,CAAC,WAAW,YAAY;AAAA,MACxB,CAAC,uBAAuB,cAAc;AAAA,MACtC,CAAC,YAAY,cAAc;AAAA,IAC7B,CAAC;AACD,UAAM,YAAY,MAAM,WACrB,IAAI,CAAC,MAAM,EAAE,IAAI,EACjB,KAAK,CAAC,MAAM,0BAA0B,IAAI,CAAC,CAAC;AAE/C,QAAI,WAAW;AACb,aAAO,KAAK,UAAU,0BAA0B,IAAI,SAAS;AAAA,IAC/D,OAAO;AAGL,YAAM,uBAAuB,oBAAI,IAAI;AAAA,QACnC,CAAC,OAAO,YAAY;AAAA,QACpB,CAAC,QAAQ,YAAY;AAAA,QACrB,CAAC,SAAS,YAAY;AAAA,QACtB,CAAC,SAAS,cAAc;AAAA,QACxB,CAAC,UAAU,cAAc;AAAA,QACzB,CAAC,WAAW,cAAc;AAAA,MAC5B,CAAC;AACD,YAAM,gBAAgB,qBAAqB,IAAI,MAAM,IAAI;AAEzD,UAAI,eAAe;AACjB,eAAO,KAAK,UAAU;AAAA,MACxB,OAAO;AACL,eAAO;AAAA,MACT;AAAA,IACF;AAAA,EACF,OAAO;AACL,WAAO;AAAA,EACT;AACF;AAEA,eAAe,uBAAuB,cAAqC;AACzE,QAAM;AAAA,IACJ,QAAQ,UAAU,uBAAuB,YAAY;AAAA,IACrD;AAAA,EACF;AACF;AAEA,eAAe,qBAAqB,cAAqC;AACvE,QAAM;AAAA,IACJ,QAAQ,UAAU,uBAAuB,YAAY;AAAA,IACrD;AAAA,EACF;AACF;AAEA,eAAe,oBACb,SACA,QACe;AACf,SAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;AACtC,UAAM,OAAO,KAAK,SAAS,EAAE,KAAK,QAAQ,GAAG,CAAC,OAAO,SAAS,YAAY;AACxE,UAAI,OAAO;AACT,gBAAQ,MAAM,KAAK;AAAA,MACrB;AAAA,IACF,CAAC;AAED,SAAK,GAAG,SAAS,CAAC,SAAS;AACzB,UAAI,SAAS,GAAG;AAEd,gBAAQ;AAAA,MACV,OAAO;AACL,eAAO,SAAS,IAAI;AAAA,MACtB;AAAA,IACF,CAAC;AAAA,EACH,CAAC;AACH;AAMA,eAAe,gBACb,UACA,SACA,WACkB;AAClB,QAAM,UAAU,IAAI,IAAI,QAAQ;AAChC,QAAM,UAAU,KAAK,KAAK,WAAW,gBAAgB;AACrD,QAAM,gBACJ,QAAQ,aAAa,UACjB,OACA,QAAQ,aAAa,WACrB,QACA;AAEN,MAAI,kBAAkB;AACpB,UAAM,IAAI;AAAA,MACR,aAAa,QAAQ,QAAQ;AAAA,IAC/B;AAEF,QAAM,mBAAmB,MAAM,IAAI,QAAiB,CAAC,SAAS,WAAW;AACvE,UAAM,MAAM,cAAc,IAAI,SAAS,CAAC,aAAa;AACnD,UAAI,SAAS,eAAe,KAAK;AAE/B,gBAAQ,KAAK;AAAA,MACf,WAAW,SAAS,eAAe,KAAK;AACtC,cAAM,oBAAoB,kBAAkB,OAAO;AACnD,iBAAS,KAAK,iBAAiB;AAC/B,0BAAkB,GAAG,UAAU,MAAM,QAAQ,IAAI,CAAC;AAAA,MACpD,OAAO;AAEL;AAAA,UACE,iDAAiD,SAAS,UAAU;AAAA,QACtE;AAAA,MACF;AAAA,IACF,CAAC;AAED,QAAI,GAAG,SAAS,MAAM;AAAA,EACxB,CAAC;AAGD,MAAI,kBAAkB;AACpB,UAAM,WAAW,SAAS,OAAO;AAAA,EACnC;AAEA,SAAO;AACT;AAEA,SAAS,mBACP,MACA,YACA;AACA,QAAM,YAAY,KAAK,QAAQ,KAAK,OAAO,WAAW;AACtD,QAAM,qBACJ,eAAe,WAAW,2BAA2B;AACvD,SAAO,KAAK,KAAK,WAAW,kBAAkB;AAChD;AAEA,SAAS,sBAAsB,MAAsB;AACnD,SAAO,KAAK,OAAO,CAAC,EAAE,YAAY,IAAI,KAAK,UAAU,CAAC;AACxD;AAsBA,SAAS,eAAe,KAAqB;AAC3C,QAAM,eAAe;AACrB,SAAO,IAAI,WAAW,cAAc,EAAE;AACxC;AAQA,SAAS,YAAY,MAA4B;AAI/C,QAAM,aACJ;AACF,QAAM,eAAe,CAAC,GAAG,KAAK,SAAS,UAAU,CAAC;AAClD,QAAMC,MAAK,aAAa;AAAA,IACtB,CAAC,UACC,MAAM;AAAA,EACV;AAEA,SAAOA,IAAG,IAAI,CAAC,OAAO;AAAA,IACpB,GAAG;AAAA,IACH,YAAY,gBAAgB,EAAE,cAAc,EAAE;AAAA,EAChD,EAAE;AACJ;AAQA,SAAS,gBAAgB,YAAsC;AAK7D,QAAM,iBAAiB;AACvB,QAAM,UAAU,CAAC,GAAG,WAAW,SAAS,cAAc,CAAC;AACvD,SAAO,QAAQ,IAAI,CAAC,MAAM;AACxB,UAAM,EAAE,MAAM,KAAK,IAAI,EAAE;AACzB,UAAM,WAAW,MAAM,UAAU,GAAG,KAAK,SAAS,CAAC;AACnD,UAAM,aAAa,UAAU,MAAM,GAAG,GAAG,IAAI,CAAC,QAAQ,IAAI,KAAK,CAAC,KAAK,CAAC;AACtE,WAAO;AAAA,MACL;AAAA,MACA,MAAM;AAAA,IACR;AAAA,EACF,CAAC;AACH;AAKA,SAAS,eAAe,WAAkC;AACxD,QAAM,gBAAgB,KAAK,KAAK,WAAW,YAAY;AACvD,QAAM,sBAAsB;AAC5B,QAAM,cAAc;AACpB,SAAO,qBAAqB,qBAAqB,aAAa,aAAa;AAC7E;AAKA,SAAS,qBAAqB,WAAkC;AAC9D,QAAM,gBAAgB,KAAK,KAAK,WAAW,YAAY;AACvD,SAAO,GAAG;AAAA,IACR;AAAA;AAAA,IAEA;AAAA,EACF;AACF;AAEA,eAAe,sBAAsB,WAAkC;AACrE,QAAM,WAAW,MAAM,GAAG,QAAQ,SAAS;AAE3C,QAAM,QAAQ,SAAS,IAAI,OAAO,cAAc;AAC9C,UAAM,WAAW,KAAK,KAAK,WAAW,SAAS;AAC/C,QAAI,cAAc,cAAc;AAE9B,aAAO,GAAG,OAAO,UAAU,KAAK,KAAK,WAAW,mBAAmB,CAAC;AAAA,IACtE,WAAW,cAAc,YAAY;AAEnC,aAAO,GAAG,GAAG,UAAU,EAAE,WAAW,KAAK,CAAC;AAAA,IAC5C;AAAA,EACF,CAAC;AACD,QAAM,QAAQ,IAAI,KAAK;AACzB;AAEA,eAAe,0BAA0B,WAAkC;AACzE,QAAM,OAAO,KAAK,KAAK,WAAW,UAAU;AAC5C,QAAM,UAAU,MAAM,GAAG,SAAS,MAAM,MAAM;AAC9C,QAAM,aAAa,QAChB,QAAQ,wBAAwB,yBAAyB,EACzD,QAAQ,0BAA0B,2BAA2B;AAChE,QAAM,GAAG,UAAU,MAAM,UAAU;AACrC;AAEA,eAAe,qBAAqB,eAAuB;AACzD,SAAO;AAAA,IACL,WAAW,MAAM,QAAQ;AAAA,IACzB,gBAAgB,MAAM,QAAQ,GAAG,SAAS;AAAA,IAC1C,eAAe,MAAM,QAAQ;AAAA,IAC7B,cAAc;AAAA,IACd,eAAe;AAAA,IACf,sBAAsB;AAAA;AAAA,IAEtB,gBAAgB,GAAG,aAAa,eAAe,KAAK,OAAO,EACxD,SAAS,EAAE,EACX,MAAM,CAAC,CAAC;AAAA,EACb;AACF;AAEA,SAAS,qBAAqB,KAAqB;AACjD,QAAM,SAAS,IAAI,IAAI,GAAG;AAC1B,MAAI,OAAO,UAAU;AACnB,WAAO,WAAW;AAAA,EACpB;AACA,SAAO,OAAO,SAAS;AACzB;","names":["require","modelName","fs"]}